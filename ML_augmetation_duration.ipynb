{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_augmetation_duration.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NLT_V5PD72l6",
        "hE04g_ChDl26",
        "7jdAFNzEEChw"
      ],
      "authorship_tag": "ABX9TyMmKfTVRNxbyCrlNtuIJN2X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryu0315360/Testing/blob/main/ML_augmetation_duration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# library & class define"
      ],
      "metadata": {
        "id": "NLT_V5PD72l6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fgDA31Q4O05",
        "outputId": "36af05de-1c71-4ad3-e571-8f2fe3f23176"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras.utils\n",
            "  Downloading keras-utils-1.0.13.tar.gz (2.4 kB)\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.7/dist-packages (from keras.utils) (2.8.0)\n",
            "Building wheels for collected packages: keras.utils\n",
            "  Building wheel for keras.utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras.utils: filename=keras_utils-1.0.13-py3-none-any.whl size=2656 sha256=aa65f257c65e234392f8f28ba04c588c3752d96a43ac9479bb565f0bdaa0139e\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/dd/3b/493952a5240d486a83805d65360dedadbadeae71d25e2c877f\n",
            "Successfully built keras.utils\n",
            "Installing collected packages: keras.utils\n",
            "Successfully installed keras.utils-1.0.13\n"
          ]
        }
      ],
      "source": [
        "!pip install keras.utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Y6FCemDb-Ow"
      },
      "outputs": [],
      "source": [
        "# Keras\n",
        "import keras\n",
        "from keras import regularizers\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential, Model, model_from_json\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.callbacks import (EarlyStopping, LearningRateScheduler,\n",
        "                             ModelCheckpoint, TensorBoard, ReduceLROnPlateau)\n",
        "from keras import losses, models, optimizers\n",
        "from keras.activations import relu, softmax\n",
        "from keras.layers import (Convolution2D, GlobalAveragePooling2D, BatchNormalization, Flatten, Dropout,\n",
        "                          GlobalMaxPool2D, MaxPool2D, concatenate, Activation, Input, Dense)\n",
        "\n",
        "# sklearn\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Other  \n",
        "from tqdm import tqdm, tqdm_pandas\n",
        "import scipy\n",
        "from scipy.stats import skew\n",
        "\n",
        "import json\n",
        "import tensorflow as tf\n",
        "from matplotlib.pyplot import specgram\n",
        "\n",
        "import IPython.display as ipd  # To play sound in the notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgToxuQVq93n"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import soundfile\n",
        "import os, glob, pickle, sys\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# to play the audio files\n",
        "from IPython.display import Audio\n",
        "\n",
        "import keras\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
        "# from keras.utils import np_utils, to_categorical\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUzo2SguDpCW"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "if not sys.warnoptions:\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKaGPl9ew5v_",
        "outputId": "c6cde49c-4b0c-4fee-8547-736e7ea04595"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "## path!\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "path_orig = 'gdrive/MyDrive/data/audio_speech_actors_01-24/Actor_*/*.wav' ## RAVDESS before padding \n",
        "path_tess = 'gdrive/MyDrive/TESS_Data/dataverse_files/*.wav'  ## tess before padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04JI7Y_orB4K"
      },
      "outputs": [],
      "source": [
        "## from 2sec data (after duration processing)\n",
        "\n",
        "path_orig2 = 'gdrive/MyDrive/data/audio_speech_actors_01-24/2sec_data/*.wav' ## RAVDESS before padding \n",
        "path_tess2 = 'gdrive/MyDrive/TESS_Data/2sec_data/*.wav' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES-dt6EjWYha",
        "outputId": "44ea8993-ff51-4a0a-e406-82778d9dd0b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install audiomentations"
      ],
      "metadata": {
        "id": "BIDMLaka9yfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install audioread"
      ],
      "metadata": {
        "id": "nW64586aDqHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bu0EghXMWPYZ"
      },
      "outputs": [],
      "source": [
        "from pydub import AudioSegment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgAJLNN6uDPa"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras.layers as tfl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTUf_r9HAMFa"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "random.seed(299)\n",
        "np.random.seed(299)\n",
        "tf.random.set_seed(299)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLfc7lL5ySrU"
      },
      "outputs": [],
      "source": [
        "# Emotions in the RAVDESS dataset\n",
        "emotions={\n",
        "  '01':'neutral',\n",
        "  '02':'calm',\n",
        "  '03':'happy',\n",
        "  '04':'sad',\n",
        "  '05':'angry',\n",
        "  '06':'fearful',\n",
        "  '07':'disgust',\n",
        "  '08':'surprised'\n",
        "}\n",
        "# Emotions to observe\n",
        "# observed_emotions=['calm', 'happy', 'fearful', 'disgust']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_tess = {\n",
        "  'neutral':'neutral',\n",
        "  # '02':'calm',\n",
        "  'happy':'happy',\n",
        "  'sad':'sad',\n",
        "  'angry':'angry',\n",
        "  'fear':'fearful',\n",
        "  'disgust':'disgust',\n",
        "  # '08':'surprised'\n",
        "}"
      ],
      "metadata": {
        "id": "2BU8hIYN-vsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# augmentation"
      ],
      "metadata": {
        "id": "hE04g_ChDl26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Augmentation (X3) # 13 min 31 sec\n",
        "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "\n",
        "# augment = Compose([\n",
        "#     # AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
        "#     TimeStretch(min_rate=0.8, max_rate=1.25, p=1),\n",
        "#     # PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
        "#     Shift(min_fraction=-0.5, max_fraction=0.5, p=0.5),\n",
        "# ])\n",
        "\n",
        "# Generate 2 seconds of dummy audio for the sake of example\n",
        "# samples = np.random.uniform(low=-0.2, high=0.2, size=(32000,)).astype(np.float32)\n",
        "\n",
        "# print(samples)\n",
        "\n",
        "# Augment/transform/perturb the audio data\n",
        "# augmented_samples = augment(samples=samples, sample_rate=16000)\n",
        "\n",
        "augment_stretch = Compose([\n",
        "    TimeStretch(min_rate=0.8, max_rate=1.25, p=1)\n",
        "])\n",
        "\n",
        "augment_noise = Compose([\n",
        "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=1)\n",
        "])\n",
        "\n",
        "for file in glob.glob(path_tess):\n",
        "\n",
        "  try:\n",
        "    file_name = os.path.basename(file)\n",
        "    y, sr = librosa.load(file)\n",
        "  \n",
        "  except:\n",
        "    print(\"decoding error\")\n",
        "    continue\n",
        "\n",
        "  # for i in range(3):\n",
        "  augmented_samples = augment_stretch(samples=y, sample_rate=sr)\n",
        "  name = str(file)[:-4] + \"_augS_\" + str(i+1) + '.wav' \n",
        "  # name = \"aug_\" + str(i+1) + \"_\" + str(file)\n",
        "  print(name)\n",
        "  sf.write(name, augmented_samples, sr)\n",
        "\n",
        "  augmented_samples = augment_noise(samples=y, sample_rate=sr)\n",
        "  name = str(file)[:-4] + \"_augN_\" + str(i+1) + '.wav' \n",
        "  # name = \"aug_\" + str(i+1) + \"_\" + str(file)\n",
        "  print(name)\n",
        "  sf.write(name, augmented_samples, sr)\n",
        "\n",
        "for file in glob.glob(path_orig):\n",
        "\n",
        "  try:\n",
        "    file_name = os.path.basename(file)\n",
        "    y, sr = librosa.load(file)\n",
        "  \n",
        "  except:\n",
        "    print(\"decoding error\")\n",
        "    continue\n",
        "\n",
        "  # for i in range(3):\n",
        "  augmented_samples = augment_stretch(samples=y, sample_rate=sr)\n",
        "  name = str(file)[:-4] + \"_augS_\" + str(i+1) + '.wav' \n",
        "  # name = \"aug_\" + str(i+1) + \"_\" + str(file)\n",
        "  print(name)\n",
        "  sf.write(name, augmented_samples, sr)\n",
        "\n",
        "  augmented_samples = augment_noise(samples=y, sample_rate=sr)\n",
        "  name = str(file)[:-4] + \"_augN_\" + str(i+1) + '.wav' \n",
        "  # name = \"aug_\" + str(i+1) + \"_\" + str(file)\n",
        "  print(name)\n",
        "  sf.write(name, augmented_samples, sr)\n"
      ],
      "metadata": {
        "id": "92-ArECADe1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# duration setting"
      ],
      "metadata": {
        "id": "7jdAFNzEEChw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_duration_error():\n",
        "  cnt = 0\n",
        "  for file in glob.glob(path_tess2):\n",
        "    cnt += 1\n",
        "    sound = AudioSegment.from_wav(file)\n",
        "    sound = sound.set_channels(1)\n",
        "\n",
        "    if sound.duration_seconds != float(2.0):\n",
        "      print(\"duration error\")\n",
        "      print(file)\n",
        "      print(sound.duration_seconds)\n",
        "\n",
        "  print(cnt)\n",
        "\n",
        "\n",
        "check_duration_error()"
      ],
      "metadata": {
        "id": "rHRqINDLEESm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def padding_duration():\n",
        "  for file in glob.glob(path_tess):\n",
        "    try:\n",
        "      file_name=os.path.basename(file)\n",
        "\n",
        "      if file_name.split('_')[2] == 'ps.wav':\n",
        "        print(\"ps\")\n",
        "        continue\n",
        "      # y, sr = librosa.load(file_name, offset=1.0, duration=3.0)\n",
        "      sound = AudioSegment.from_wav(file)\n",
        "      sound = sound.set_channels(1)\n",
        "    except:\n",
        "      print(\"Decoding error\")\n",
        "      continue\n",
        "\n",
        "    pad_ms = 2000  # milliseconds of silence needed # 3sec\n",
        "\n",
        "    #print(\"before duration: \", sound.duration_seconds)\n",
        "\n",
        "    if float(sound.duration_seconds) < float(2.0): \n",
        "      print(\"shorter than 2\")\n",
        "      silence = AudioSegment.silent(duration = 1000)\n",
        "      # print(\"temp: \", temp)\n",
        "      print(\"sound duration: \",sound.duration_seconds)\n",
        "      # audio = AudioSegment.from_wav(file)\n",
        "      sound = silence + sound + silence  # Adding silence after the audio\n",
        "      mid_duration = int((sound.duration_seconds/2)*1000)\n",
        "      sound = sound[mid_duration - 1000:mid_duration+1000]\n",
        "      print(\"new sound duration: \", sound.duration_seconds)\n",
        "      new_filename = '/'.join(file.split('/')[:-2]) + \"/2sec_data/\" + '/'.join(file.split('/')[-1:])\n",
        "      # print(new_filename)\n",
        "      sound.export(new_filename, format='wav')\n",
        "    else:\n",
        "      print(\"longer than 2\")\n",
        "      mid_duration = int((sound.duration_seconds/2)*1000)\n",
        "      print(mid_duration)\n",
        "      sound = sound[mid_duration - 1000:mid_duration +1000]\n",
        "      new_filename = '/'.join(file.split('/')[:-2]) + \"/2sec_data/\" + '/'.join(file.split('/')[-1:])\n",
        "      print(\"new sound duration: \", sound.duration_seconds)\n",
        "      # print(new_filename)\n",
        "      sound.export(new_filename, format=\"wav\") ## exporting to new folder!!\n",
        "    \n",
        "    #print(\"after duration: \", sound.duration_seconds)\n",
        "\n",
        "    if sound.duration_seconds != 2.0:\n",
        "      print(\"duration error\")\n",
        "      return 0\n",
        "\n",
        "  for file in glob.glob(path_orig):\n",
        "    try:\n",
        "      file_name=os.path.basename(file)\n",
        "      print(file)\n",
        "\n",
        "      # y, sr = librosa.load(file_name, offset=1.0, duration=3.0)\n",
        "      sound = AudioSegment.from_wav(file)\n",
        "      sound = sound.set_channels(1)\n",
        "    except:\n",
        "      print(\"Decoding error\")\n",
        "      continue\n",
        "\n",
        "    pad_ms = 2000  # milliseconds of silence needed # 3sec\n",
        "\n",
        "    #print(\"before duration: \", sound.duration_seconds)\n",
        "\n",
        "    if float(sound.duration_seconds) < float(2.0): \n",
        "      print(\"shorter than 2\")\n",
        "\n",
        "      silence = AudioSegment.silent(duration = 1000)\n",
        "      # print(\"temp: \", temp)\n",
        "      print(\"sound duration: \",sound.duration_seconds)\n",
        "      # audio = AudioSegment.from_wav(file)\n",
        "      sound = silence + sound + silence  # Adding silence after the audio\n",
        "      mid_duration = int((sound.duration_seconds/2)*1000)\n",
        "      sound = sound[mid_duration - 1000:mid_duration+1000]\n",
        "      print(\"new sound duration: \", sound.duration_seconds)\n",
        "      new_filename = '/'.join(file.split('/')[:-2]) + \"/2sec_data/\" + '/'.join(file.split('/')[-1:])\n",
        "      # print(new_filename)\n",
        "      sound.export(new_filename, format='wav')\n",
        "    else:\n",
        "      print(\"longer than 2\")\n",
        "      mid_duration = int((sound.duration_seconds/2)*1000)\n",
        "      print(mid_duration)\n",
        "      sound = sound[mid_duration - 1000:mid_duration +1000]\n",
        "      new_filename = '/'.join(file.split('/')[:-2]) + \"/2sec_data/\" + '/'.join(file.split('/')[-1:])\n",
        "      print(\"new sound duration: \", sound.duration_seconds)\n",
        "      print(new_filename)\n",
        "      try:\n",
        "        sound.export(new_filename, format=\"wav\")\n",
        "      except:\n",
        "        print('export 안됨')\n",
        "        continue\n",
        "    \n",
        "    #print(\"after duration: \", sound.duration_seconds)\n",
        "\n",
        "    if sound.duration_seconds != 2.0:\n",
        "      print(\"duration error\")\n",
        "      return 0\n",
        "\n",
        "  \n",
        "\n",
        "  return 0\n",
        "\n",
        "padding_duration()"
      ],
      "metadata": {
        "id": "5WXFqcquEHlJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}